{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflowを使ってみる\n",
    "\n",
    "まずは線形回帰で\n",
    "\n",
    "$$y = 0.1 * x  + 0.3$$ \n",
    "\n",
    "を学習することをやってみる。\n",
    "\n",
    "まずは、ランダムに`x_data`を生成して、そこから上記の数式に値をいれた`y_data`を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data ->  [ 0.40428349  0.50799495  0.73364222  0.55786508  0.37450069]\n",
      "y_data ->  [ 0.34042835  0.3507995   0.37336424  0.35578653  0.33745009]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.random.rand(100).astype(\"float32\")\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "print(\"x_data -> \", x_data[:5])\n",
    "print(\"y_data -> \", y_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、学習するモデルを\n",
    "\n",
    "$$ y = W * x  + b $$\n",
    "\n",
    "とおいて、`W`と`b`を変数とする。そのため、tensorflowのVariableとして定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x10220eef0> <tensorflow.python.ops.variables.Variable object at 0x1073a1828>\n",
      "Tensor(\"add:0\", shape=TensorShape([Dimension(100)]), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1, 1))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "print(W,b)\n",
    "y = W * x_data + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print`するとtensoflowのVariableとして定義されていることがわかる。また、`y`はTenorのインスタンスで、`\"add:0\"`という表現を持っていることがわかる。\n",
    "\n",
    "さて、学習するために、コスト関数を定義する。またその後、コスト関数を最小化するための手法として最急降下法のインスタンスを、学習率0.5で生成し、コスト関数を最小化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss-> Tensor(\"Mean:0\", shape=TensorShape([]), dtype=float32)\n",
      "optimizer-> <tensorflow.python.training.gradient_descent.GradientDescentOptimizer object at 0x107466780>\n",
      "train-> name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_Variable_1/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "print(\"loss->\", loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "print(\"optimizer->\", optimizer)\n",
    "train = optimizer.minimize(loss)\n",
    "print(\"train->\", train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべての値を初期化する。この場合、初期化されるのは、`W`と`b`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflowを実行するときには、Sessionを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sessionはrunすることにより、Tensorのインスタンスを実行したり、Variableを表示したりすることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.06070527] [ 0.44151741]\n",
      "20 [ 0.07319944] [ 0.31429142]\n",
      "40 [ 0.09196129] [ 0.30428666]\n",
      "60 [ 0.09758884] [ 0.30128577]\n",
      "80 [ 0.0992768] [ 0.30038565]\n",
      "100 [ 0.09978308] [ 0.30011567]\n",
      "120 [ 0.09993493] [ 0.3000347]\n",
      "140 [ 0.09998049] [ 0.30001041]\n",
      "160 [ 0.09999416] [ 0.30000314]\n",
      "180 [ 0.09999826] [ 0.30000094]\n",
      "200 [ 0.09999949] [ 0.30000028]\n"
     ]
    }
   ],
   "source": [
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINISTをパーセプトロンで学習してみる\n",
    "\n",
    "まずは、簡単なパーセプトロンで学習する。Tensorflowのチュートリアルだと、input_data.pyを使うみたいだけど、せっかくなので,Theanoのチュートリアルに合わせて、minist.pkl.gzを使う\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n",
      "784\n",
      "28x28の画像のモノクロ(白0→黒1)が１次元配列で入っている [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "最初のラベルは 5\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip\n",
    "f = gzip.open('data/mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "print(len(train_set[0]), len(valid_set[0]), len(test_set[0]))\n",
    "train_set_x, train_set_y = train_set\n",
    "test_set_x, test_set_y = test_set\n",
    "print(len(train_set_x[0]))\n",
    "print(\"28x28の画像のモノクロ(白0→黒1)が１次元配列で入っている\",train_set_x[:5])\n",
    "print(\"最初のラベルは\",train_set_y[0])\n",
    "\n",
    "# ベクトルに変換する\n",
    "def num_to_vec(num):\n",
    "    vec = np.zeros(10)\n",
    "    vec[num] = 1\n",
    "    return vec\n",
    "\n",
    "train_set_y_vec = np.array([num_to_vec(num) for num in train_set_y])\n",
    "test_set_y_vec =  np.array([num_to_vec(num) for num in test_set_y])\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後のアウトプットの数字は10次元のベクトル空間上の元として考える。例えば5は$[0,0,0,0,1,0,0,0,0,0]\\in\\mathbb{R}^{10}$で表現される。また、入力データは784次元なので、ネットワークの重み$W$は784x10の行列で表し、$\\vec{evidence}$を\n",
    "\n",
    "$$ \\vec{evidence} = W \\cdot \\vec{x} + \\vec{b}$$\n",
    "\n",
    "\n",
    "とし、ソフトマックスを活性化関数として適用したものを予想値とする。$\\vec{x}$の$i$要素に対して、ソフトマックスの各要素は\n",
    "\n",
    "$$ softmax_{i} = \\frac{\\exp{(x_{i})}}{\\sum_{j}\\exp(x_{j})} $$\n",
    "\n",
    "と定義する。これをベクトルに適用し、\n",
    "\n",
    "$$ y = softmax(\\vec{evidence}) $$\n",
    "\n",
    "を予想値しこれで学習する。最終的には\n",
    "\n",
    "$$ y_{predict} = argmax_{i}softmax_{i}(\\vec{evidence}) $$\n",
    "\n",
    "で予想する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`placefolder`はあとで、`sess.run`の時に、`feed_dict`で値を入れることができる。1変数目は型で、2変数目はサイズ。ここで、Noneとなっているのは任意の値の意味。入力の数はデータセットやミニバッチの数に酔って変わるので任意の値にしておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# これは答えを入れる\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のコスト関数はクロスエントロピーを使う。0~1の値なので、logはマイナスの値を取り、0の近くではマイナス無限大に発散する。そのため、値が外れていた時には、クロスエントロピーは無限大に近い値を取るので、とても学習が進む。またy_をかけているため、答えの要素のみが大きく影響することになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習は最急降下法で行う。学習率は0.01で、クロスエントロピーを最小化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習はミニバッチで行う。データ量が多いのため、全データでの学習をするととても時間がかかる。そのため、データを分割して学習する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "for step in range(1000):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = train_set_x[batch_index:batch_index+batch_size]\n",
    "    batch_y = train_set_y_vec[batch_index:batch_index+batch_size]    \n",
    "    sess.run(train_step, feed_dict={x:batch_x, y_:batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで学習が終わったので、テストデータを使って学習する。正解している数の平均を正答率とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9126\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.arg_max(y, 1), tf.arg_max(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print (sess.run(accuracy, feed_dict={x:test_set_x, y_:test_set_y_vec}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90%ぐらいの精度が出る"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
