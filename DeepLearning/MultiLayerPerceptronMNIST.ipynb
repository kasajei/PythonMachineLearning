{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "\n",
    "パーセプトロンを複数レイヤーつなげて、学習させてみる。活性化関数としては、reluを使い、最後の評価は`L.Classifier`のデフォルトで使うことにする。最適化アルゴリズムはAdamを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n",
      "784\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "28x28の画像のモノクロ(白0→黒1)が１次元配列で入っている [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "最初のラベルは 5\n",
      "[5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip\n",
    "f = gzip.open('../data/mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "print(len(train_set[0]), len(valid_set[0]), len(test_set[0]))\n",
    "train_set_x, train_set_y  = train_set\n",
    "test_set_x, test_set_y = test_set\n",
    "print(len(train_set_x[0]))\n",
    "print(train_set_x)\n",
    "print(\"28x28の画像のモノクロ(白0→黒1)が１次元配列で入っている\",train_set_x[:5])\n",
    "print(\"最初のラベルは\",train_set_y[0])\n",
    "\n",
    "# あとで、softmax_cross_entropyを使うときに型の判定があり、np.int32じゃないといけない\n",
    "train_set_y = train_set_y.astype(np.int32)\n",
    "test_set_y = test_set_y.astype(np.int32)\n",
    "print(train_set_y )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABW5JREFUeJzt3T0otX8cx/Fz/mQgD1ncpSQGSsSAkpIkKQaxUBZsyGSx\nGUhhQAaTMsiKifI4KCUPC9k9bB6Thzzc+//7u3XhfM7l4v0aP//jnKv+7676Obdzwm9vbyFA6T+/\nLwA/H5FBjsggR2SQIzLIxb73H8PhMEdPfMjb21v4/xt3MsgRGeSIDHJEBjkigxyRQY7IIEdkkCMy\nyBEZ5IgMckQGOSKDHJFBjsggR2SQIzLIERnkiAxyRAY5IoMckUGOyCBHZJAjMsi9+xfkv1VMTIzZ\nkpOTP/18XV1dzj0+Pt5sOTk5Zuvs7DTbyMiI2Zqbm8328PDgfO2hoSGz9ff3Ox/7VdzJIEdkkCMy\nyBEZ5IgMcoE/XWZkZJgtLi7ObGVlZc6fLy8vN1tKSorZGhsbP3F1H3dycmK28fFxszU0NJjt9vbW\nbAcHB87X2djY+MTVfQ53MsgRGeSIDHJEBjkig1z4ve9W+m6ffl1UVGS2lZUVs33lfcZoen19NVtb\nW5vZ7u7uPD3f2dmZ2S4vL52PPT4+9vScH8WnX8MXRAY5IoMckUGOyCAXqNNlamqq2ba3t82WlZUV\njctxvvbV1ZXZKisrnT//9PRktqCcjP+F0yV8QWSQIzLIERnkiAxygfqXsRcXF2br7e01W11dndn2\n9vacz+n6V6cu+/v7Zquurjab633GvLw853P29PR4eu2g404GOSKDHJFBjsggR2SQIzLIBeoNcq+S\nkpLM5vrD11AoFJqamjJbe3u72VpbW802Ozv7iav72XiDHL4gMsgRGeSIDHJEBrlAvUHu1c3NjefH\nXl9fe3pcR0eH2ebm5szm+oPd3447GeSIDHJEBjkigxyRQe5Hvnf5EQkJCWZbXFw0W0VFhdlqa2vN\ntry8HJkLCyjeu4QviAxyRAY5IoMckUHu158uXbKzs822u7trNtfHRK2trZltZ2fH+TqTk5Nme+//\nRxBwuoQviAxyRAY5IoMckUGO06VHri8xnZ6eNltiYqLn5+zr6zPbzMyM2c7Pzz0/p984XcIXRAY5\nIoMckUGOyCBHZJDjVxhfkJ+fb7bR0VGzVVVVeX5O10dZDQwMmO309NTzc0YTv8KAL4gMckQGOSKD\nHJFBjtNlhKWkpJitvr7e+VjXG+zhsDmchVZXV83m+l6n74DTJXxBZJAjMsgRGeSIDHKcLn30+Pho\ntthY+1nRz8/PZqupqTHb+vp6RK7rKzhdwhdEBjkigxyRQY7IIPcjv/YmWgoKCszW1NRktuLiYufP\nu06SLoeHh2bb3Nz09LPfAXcyyBEZ5IgMckQGOSKDHKdLh5ycHLN1d3ebzfVxUn/+/PnSa7+8vJjN\n9dFRQfryVu5kkCMyyBEZ5IgMckQGOSKD3K/5Fca/frXQ0tJits7OTrNlZmZG+pKc37nk+piohYWF\niL92NHEngxyRQY7IIEdkkCMyyAX+dJmWlma2vLw8s01MTDh/Pjc3N6LXs729bbbh4WHnY+fn580W\npDe+veJOBjkigxyRQY7IIEdkkPu2p8vU1FSzub4SprCw0GxZWVkRv56trS2zub7iZmlpyWz39/cR\nv54g4U4GOSKDHJFBjsggR2SQi+rpsrS01Ln39vaaraSkxGzp6ekRvybXyW9sbMxsg4ODZru7u4v4\n9fxE3MkgR2SQIzLIERnkiAxyUT1duj5q6b3di6OjI7MtLi6azfWRTKFQKDQyMmK2q6urT18PLO5k\nkCMyyBEZ5IgMckQGOSKDHN/ci4jim3vhCyKDHJFBjsggR2SQIzLIERnkiAxyRAY5IoMckUGOyCBH\nZJAjMsgRGeSIDHJEBjkig9y7//waiATuZJAjMsgRGeSIDHJEBrm/Jxo0pVRchpkAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a62a080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a62a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_digit(data):\n",
    "    size = 28\n",
    "    plt.figure(figsize=(2.5, 3))\n",
    "\n",
    "    X, Y = np.meshgrid(range(size),range(size))\n",
    "    Z = data.reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "    Z = Z[::-1,:]             # flip vertical\n",
    "    plt.xlim(0,27)\n",
    "    plt.ylim(0,27)\n",
    "    plt.pcolor(X, Y, Z)\n",
    "    plt.gray()\n",
    "    plt.tick_params(labelbottom=\"off\")\n",
    "    plt.tick_params(labelleft=\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_digit(train_set_x[0])\n",
    "draw_digit(train_set_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTMLPerceptron(Chain):\n",
    "    def __init__(self, hidden_num=1024):\n",
    "        super(MNISTMLPerceptron, self).__init__(\n",
    "            l1 = L.Linear(784, hidden_num),\n",
    "            l2 = L.Linear(hidden_num, hidden_num),\n",
    "            l3 = L.Linear(hidden_num, 10)\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "    \n",
    "model = L.Classifier(MNISTMLPerceptron())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9599999785423279\n",
      "100 0.9700000286102295\n",
      "200 0.9900000095367432\n",
      "300 1.0\n",
      "400 0.9900000095367432\n",
      "500 0.9800000190734863\n",
      "600 0.949999988079071\n",
      "700 0.9700000286102295\n",
      "800 0.9599999785423279\n",
      "900 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    batch_y = Variable(train_set_y[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(model, batch_x, batch_y)\n",
    "    if step % 100 == 0:\n",
    "        print(step, model.accuracy.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9740999937057495\n"
     ]
    }
   ],
   "source": [
    "model(Variable(test_set_x),Variable(test_set_y))\n",
    "print(model.accuracy.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97%ぐらいの制度が出る\n",
    "\n",
    "次は、各層にdropoutを入れてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTMLPerceptronDropout(MNISTMLPerceptron):\n",
    "    def __call__(self, x):\n",
    "        h1 = F.dropout(F.relu(self.l1(x)))\n",
    "        h2 = F.dropout(F.relu(self.l2(h1)))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09000000357627869\n",
      "100 0.8799999952316284\n",
      "200 0.9399999976158142\n",
      "300 0.9399999976158142\n",
      "400 0.9599999785423279\n",
      "500 0.949999988079071\n",
      "600 0.8799999952316284\n",
      "700 0.949999988079071\n",
      "800 0.9100000262260437\n",
      "900 0.9100000262260437\n",
      "1000 0.9599999785423279\n"
     ]
    }
   ],
   "source": [
    "model = L.Classifier(MNISTMLPerceptronDropout())\n",
    "optimizer.setup(model)\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    batch_y = Variable(train_set_y[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(model, batch_x, batch_y)\n",
    "    if step % 100 == 0:\n",
    "        print(step, model.accuracy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541000127792358\n"
     ]
    }
   ],
   "source": [
    "model(Variable(test_set_x),Variable(test_set_y))\n",
    "print(model.accuracy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
