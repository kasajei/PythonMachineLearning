{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "\n",
    "パーセプトロンを複数レイヤーつなげて、学習させてみる。活性化関数としては、reluを使い、最後の評価は`L.Classifier`のデフォルトで使うことにする。最適化アルゴリズムはAdamを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n",
      "784\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "28x28の画像のモノクロ(白0→黒1)が１次元配列で入っている [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "最初のラベルは 5\n",
      "[5 0 4 ..., 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip\n",
    "f = gzip.open('../data/mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "print(len(train_set[0]), len(valid_set[0]), len(test_set[0]))\n",
    "train_set_x, train_set_y  = train_set\n",
    "test_set_x, test_set_y = test_set\n",
    "print(len(train_set_x[0]))\n",
    "print(train_set_x)\n",
    "print(\"28x28の画像のモノクロ(白0→黒1)が１次元配列で入っている\",train_set_x[:5])\n",
    "print(\"最初のラベルは\",train_set_y[0])\n",
    "\n",
    "# あとで、softmax_cross_entropyを使うときに型の判定があり、np.int32じゃないといけない\n",
    "train_set_y = train_set_y.astype(np.int32)\n",
    "test_set_y = test_set_y.astype(np.int32)\n",
    "print(train_set_y )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABW5JREFUeJzt3T0otX8cx/Fz/mQgD1ncpSQGSsSAkpIkKQaxUBZsyGSx\nGUhhQAaTMsiKifI4KCUPC9k9bB6Thzzc+//7u3XhfM7l4v0aP//jnKv+7676Obdzwm9vbyFA6T+/\nLwA/H5FBjsggR2SQIzLIxb73H8PhMEdPfMjb21v4/xt3MsgRGeSIDHJEBjkigxyRQY7IIEdkkCMy\nyBEZ5IgMckQGOSKDHJFBjsggR2SQIzLIERnkiAxyRAY5IoMckUGOyCBHZJAjMsi9+xfkv1VMTIzZ\nkpOTP/18XV1dzj0+Pt5sOTk5Zuvs7DTbyMiI2Zqbm8328PDgfO2hoSGz9ff3Ox/7VdzJIEdkkCMy\nyBEZ5IgMcoE/XWZkZJgtLi7ObGVlZc6fLy8vN1tKSorZGhsbP3F1H3dycmK28fFxszU0NJjt9vbW\nbAcHB87X2djY+MTVfQ53MsgRGeSIDHJEBjkig1z4ve9W+m6ffl1UVGS2lZUVs33lfcZoen19NVtb\nW5vZ7u7uPD3f2dmZ2S4vL52PPT4+9vScH8WnX8MXRAY5IoMckUGOyCAXqNNlamqq2ba3t82WlZUV\njctxvvbV1ZXZKisrnT//9PRktqCcjP+F0yV8QWSQIzLIERnkiAxygfqXsRcXF2br7e01W11dndn2\n9vacz+n6V6cu+/v7Zquurjab633GvLw853P29PR4eu2g404GOSKDHJFBjsggR2SQIzLIBeoNcq+S\nkpLM5vrD11AoFJqamjJbe3u72VpbW802Ozv7iav72XiDHL4gMsgRGeSIDHJEBrlAvUHu1c3NjefH\nXl9fe3pcR0eH2ebm5szm+oPd3447GeSIDHJEBjkigxyRQe5Hvnf5EQkJCWZbXFw0W0VFhdlqa2vN\ntry8HJkLCyjeu4QviAxyRAY5IoMckUHu158uXbKzs822u7trNtfHRK2trZltZ2fH+TqTk5Nme+//\nRxBwuoQviAxyRAY5IoMckUGO06VHri8xnZ6eNltiYqLn5+zr6zPbzMyM2c7Pzz0/p984XcIXRAY5\nIoMckUGOyCBHZJDjVxhfkJ+fb7bR0VGzVVVVeX5O10dZDQwMmO309NTzc0YTv8KAL4gMckQGOSKD\nHJFBjtNlhKWkpJitvr7e+VjXG+zhsDmchVZXV83m+l6n74DTJXxBZJAjMsgRGeSIDHKcLn30+Pho\ntthY+1nRz8/PZqupqTHb+vp6RK7rKzhdwhdEBjkigxyRQY7IIPcjv/YmWgoKCszW1NRktuLiYufP\nu06SLoeHh2bb3Nz09LPfAXcyyBEZ5IgMckQGOSKDHKdLh5ycHLN1d3ebzfVxUn/+/PnSa7+8vJjN\n9dFRQfryVu5kkCMyyBEZ5IgMckQGOSKD3K/5Fca/frXQ0tJits7OTrNlZmZG+pKc37nk+piohYWF\niL92NHEngxyRQY7IIEdkkCMyyAX+dJmWlma2vLw8s01MTDh/Pjc3N6LXs729bbbh4WHnY+fn580W\npDe+veJOBjkigxyRQY7IIEdkkPu2p8vU1FSzub4SprCw0GxZWVkRv56trS2zub7iZmlpyWz39/cR\nv54g4U4GOSKDHJFBjsggR2SQi+rpsrS01Ln39vaaraSkxGzp6ekRvybXyW9sbMxsg4ODZru7u4v4\n9fxE3MkgR2SQIzLIERnkiAxyUT1duj5q6b3di6OjI7MtLi6azfWRTKFQKDQyMmK2q6urT18PLO5k\nkCMyyBEZ5IgMckQGOSKDHN/ci4jim3vhCyKDHJFBjsggR2SQIzLIERnkiAxyRAY5IoMckUGOyCBH\nZJAjMsgRGeSIDHJEBjkig9y7//waiATuZJAjMsgRGeSIDHJEBrm/Jxo0pVRchpkAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113783198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABaFJREFUeJzt3U0opW0cx/H78DQizSxmM1MnO3bMRMSKLI2iLCSxVdOU\nGikLZDULLwuUKKkRRbIgko2ysvG2t5OawiQvTVGcZzc9Pf+/0+3ld174fpY/x7kv+nXVda77vk4k\nFosFgFJGsgeAl4+SQY6SQY6SQY6SQe6feD+MRCIsPfEgsVgs8v+MmQxylAxylAxylAxylAxylAxy\nlAxylAxylAxylAxylAxylAxylAxylAxylAxylAxylAxylAxycW+/xsOVlJSY7Nu3b+5rW1tbTTY9\nPW2y0dFRk+3u7j5idMnBTAY5SgY5SgY5SgY5SgY5Sga5SLzzyXiCPL7Pnz+bbGNjw2Rv37590nXO\nz89N9v79+ye9pwpPkCMpKBnkKBnkKBnkKBnk2CAPqayszGSLi4sme/funcnuW8FfXl6a7ObmxmTe\nSrKiosJkOzs7od4v0ZjJIEfJIEfJIEfJIEfJIPfq9y5zcnJMVlxcbLKZmRmTRaNRk0UiZuvu3tWl\ndwt1f3+/yebm5kJdp6enx2Q/fvxwr63C3iWSgpJBjpJBjpJBjpJB7tXvXU5MTJisqakpIdf2VrG5\nubkm29zcNFlVVZXJCgsLn2Vcz42ZDHKUDHKUDHKUDHKUDHKvZnXpHekUBEHw5csXk3n7gh5v1bey\nsmKygYEB9/d//fplsr29PZOdnZ2ZrLq62mRhx51ozGSQo2SQo2SQo2SQo2SQo2SQe5G3X4c90ikI\nwh/rtLa2ZjJvI72ystJkRUVF7ntOTk6a7OTkJNR4bm9vTfbnz59Q4wkC3enZ3H6NpKBkkKNkkKNk\nkKNkkEv7DfKCggKTdXZ2msw70ikIguD09NRk3sb1z58/TXZ1dWWy1dXVUJlCdna2yTo6OtzXNjc3\nq4fzFzMZ5CgZ5CgZ5CgZ5CgZ5NJqdZmVlWWywcFBk9XU1JjMOwQ4CPxvz93e3jaZt3JLB3l5ecke\nAjMZ9CgZ5CgZ5CgZ5CgZ5NJqdekdteStJD11dXVu7j2gi+fFTAY5SgY5SgY5SgY5Sga5tFpdDg0N\nmcw7LslbMb60VWRGhp0f7u7uTJYKx0kxk0GOkkGOkkGOkkGOkkGOkkEuZT/CqK2tNZl3JJR39NXy\n8rJkTKnE+7jC+1/s7+8nYjhxMZNBjpJBjpJBjpJBjpJBLmVXl97DtG/evDHZ8fGxyebn5yVjSgTv\nAea+vr5Qv+sdvtzV1fXUIT0ZMxnkKBnkKBnkKBnkKBnkUnZ1Gdb19bXJvIOFU5G3kuzu7jaZd9Dy\n0dGRybzb073DkxONmQxylAxylAxylAxylAxyab+6TIe7YL07eoPAXzU2NjaabGlpyWQNDQ1PH1iC\nMJNBjpJBjpJBjpJBjpJBLmVXl96RR15WX19vsvb2dsmYwvj+/bvJvP3IIPC/6HV2dtZk3lfzpBNm\nMshRMshRMshRMshRMshRMsil7EcY3jFIXvbhwweTjYyMmGxqasq9zu/fv01WXl5uspaWFpN9+vTJ\nZNFo1GSHh4futdfX1002NjbmvjadMZNBjpJBjpJBjpJBjpJBLmVXl2FlZmaa7OvXrya773bli4sL\nk+Xn5z96PFtbWybzjnQKgiDo7e199HXSCTMZ5CgZ5CgZ5CgZ5CgZ5CLefuDfH0Yi9/9QzNsDXFhY\nMFlpaWmo97vvG2zj/f3/5e1xzs3NmSyZt36nglgsZv7RzGSQo2SQo2SQo2SQo2SQS9nVpefjx48m\na2trM5n3MO1DVpfDw8MmGx8fN9nBwYH7nq8Zq0skBSWDHCWDHCWDHCWDXFqtLpH6WF0iKSgZ5CgZ\n5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ5CgZ\n5CgZ5CgZ5CgZ5OI+QQ48B2YyyFEyyFEyyFEyyFEyyP0L6hEuROr7KcsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1137831d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def draw_digit(data, size=28):\n",
    "    plt.figure(figsize=(2.5, 3))\n",
    "\n",
    "    X, Y = np.meshgrid(range(size),range(size))\n",
    "    Z = data.reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "    Z = Z[::-1,:]             # flip vertical\n",
    "    plt.xlim(0,size-1)\n",
    "    plt.ylim(0,size-1)\n",
    "    plt.pcolor(X, Y, Z)\n",
    "    plt.gray()\n",
    "    plt.tick_params(labelbottom=\"off\")\n",
    "    plt.tick_params(labelleft=\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_digit(train_set_x[0])\n",
    "draw_digit(train_set_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTMLPerceptron(Chain):\n",
    "    def __init__(self, hidden_num=1024, input_num = 784, output_num = 10):\n",
    "        super(MNISTMLPerceptron, self).__init__(\n",
    "            l1 = L.Linear(input_num, hidden_num),\n",
    "            l2 = L.Linear(hidden_num, hidden_num),\n",
    "            l3 = L.Linear(hidden_num, output_num)\n",
    "        )\n",
    "        self.input_num = input_num\n",
    "        self.hidden_num = hidden_num\n",
    "        self.output_num = output_num\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "    \n",
    "model = L.Classifier(MNISTMLPerceptron())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.10999999940395355\n",
      "100 0.949999988079071\n",
      "200 0.9800000190734863\n",
      "300 0.9100000262260437\n",
      "400 0.9800000190734863\n",
      "500 0.9900000095367432\n",
      "600 0.9800000190734863\n",
      "700 0.9800000190734863\n",
      "800 0.9900000095367432\n",
      "900 0.949999988079071\n",
      "1000 0.9800000190734863\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    batch_y = Variable(train_set_y[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(model, batch_x, batch_y)\n",
    "    if step % 100 == 0:\n",
    "        print(step, model.accuracy.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度 → 0.972599983215332\n"
     ]
    }
   ],
   "source": [
    "model(Variable(test_set_x),Variable(test_set_y))\n",
    "print(\"精度 →\",model.accuracy.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "97%ぐらいの制度が出る\n",
    "\n",
    "次は、各層にdropoutを入れてみる。これは一般的には過学習を防ぐためと言われている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTMLPerceptronDropout(MNISTMLPerceptron):\n",
    "    def __call__(self, x):\n",
    "        h1 = F.dropout(F.relu(self.l1(x)))\n",
    "        h2 = F.dropout(F.relu(self.l2(h1)))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.07999999821186066\n",
      "100 0.8799999952316284\n",
      "200 0.9700000286102295\n",
      "300 0.949999988079071\n",
      "400 0.9599999785423279\n",
      "500 0.9399999976158142\n",
      "600 0.9399999976158142\n",
      "700 0.9800000190734863\n",
      "800 0.9599999785423279\n",
      "900 0.9800000190734863\n",
      "1000 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "model = L.Classifier(MNISTMLPerceptronDropout())\n",
    "optimizer.setup(model)\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    batch_y = Variable(train_set_y[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(model, batch_x, batch_y)\n",
    "    if step % 100 == 0:\n",
    "        print(step, model.accuracy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度 → 0.9581000208854675\n"
     ]
    }
   ],
   "source": [
    "model(Variable(test_set_x),Variable(test_set_y))\n",
    "print(\"精度 →\",model.accuracy.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ドロップアウトしたほうが、精度が低くなった。。。あれ？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Autoencoderのファインチューニング\n",
    "\n",
    "ニューラルネットワークの階層が深くなっていくと、学習の速度が遅くなっていくことが知られている。それはパメーターの更新時が、深い階層で消失してしまうためであろうと考えられている。\n",
    "\n",
    "そのための対策法として、プレ学習というものが使われることがあり、その手法としてAutoencoderという教師なし学習が使われることがある。\n",
    "\n",
    "Autoencoderは入力層をそっくりそのまま出力層で再現するニューラルネットワークで、その学習したパラメーターを初期値として、クラス分類のニューラルネットワークを作ろうとする。\n",
    "\n",
    "そうすることにより、よりよい学習が行われる。\n",
    "\n",
    "まずはAutoencorderを作ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Autoencoder(Chain):\n",
    "    def __init__(self, input_layer_num = 784, hidden_layer_num=1024):\n",
    "        super(Autoencoder, self).__init__(\n",
    "            l1 = L.Linear(input_layer_num, hidden_layer_num),\n",
    "            l2 = L.Linear(hidden_layer_num, input_layer_num)\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h2 = self.predict(x)\n",
    "        self.accuracy = F.mean_squared_error(h2, x)\n",
    "        return self.accuracy\n",
    "    \n",
    "    def predict(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = self.l2(h1)\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15395627915859222\n",
      "100 0.012477193027734756\n",
      "200 0.006809466518461704\n",
      "300 0.005883700214326382\n",
      "400 0.003752612741664052\n",
      "500 0.002853567246347666\n",
      "600 0.0028303395956754684\n",
      "700 0.002062590792775154\n",
      "800 0.0022276584059000015\n",
      "900 0.0028191173914819956\n",
      "1000 0.0019323721062391996\n"
     ]
    }
   ],
   "source": [
    "a1 = Autoencoder()\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(a1)\n",
    "\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(a1, batch_x)\n",
    "    if step % 100 == 0:\n",
    "        print(step, a1.accuracy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict1 = a1.predict(Variable(test_set_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABKVJREFUeJzt3T1LXHkcR/F1XYuAjREFCx/ALk2QIAgqKDY+lPoWtDE2\nQmp7yxS+AxtBsBARQUELk8JGfEJRCxURhEmhgiSC222xv39kzMyZq875lF8d5xaHC3euM1Px+Pj4\nl0T6O+sD0NtnZMIZmXBGJpyRCffPUz+sqKjw0lPP8vj4WPH/zTOZcEYmnJEJZ2TCGZlwRiackQln\nZMIZmXBGJpyRCWdkwhmZcEYmnJEJZ2TCGZlwRiackQlnZMIZmXBGJpyRCWdkwhmZcEYmnJEJZ2TC\nGZlwRiackQlnZMIZmXBGJpyRCWdkwhmZcE9++nWWRkZGwjY6Ohq2y8vLsN3f34dtdnY2+TxXV1dh\nOz4+zucQlSfPZMIZmXBGJpyRCWdkwlU89c29WX630unpadhaWlqK/jw3Nzdh29vbK/rzFNvFxUXY\npqenw7a1tVWKw/mP362kTBiZcEYmnJEJZ2TCvdh7l6n7lB8/fgzb/v5+2D58+BC2tra25PP09PSE\nraOjI2zn5+dha2xsTP7NfD08PITt+vo6bA0NDXn9vbOzs7CV+uoyxTOZcEYmnJEJZ2TCGZlwRibc\ni71BXio1NTVhS73ckXopoL29vaDnTv2b+NHRUdgODg7C9v79+7B9/vw5bDMzM394dH/GG+TKhJEJ\nZ2TCGZlwRiZc2V9dvjTDw8Nhm5ubC9vu7m7Yent7w5bL5YpzYHny6lKZMDLhjEw4IxPOyITz6jJD\n9fX1YdvZ2cnr91IfrTU/P1+cAyuAV5fKhJEJZ2TCGZlwRibci31zbzkYHx8PW11dXdh+/PgRtsPD\nQ+SYCJ7JhDMy4YxMOCMTzsiE895lCXR2dib3tbW1sFVVVYUt9fFWGxsbBR8XwXuXyoSRCWdkwhmZ\ncEYmnJEJ5w3yEhgcHEzuqZcrVldXw/bt27eiH1MpeSYTzsiEMzLhjEw4IxPOq8sie/fuXdj6+/uT\nv/vz58+wTU1Nhe3Xr1+FH1iGPJMJZ2TCGZlwRiackQnn1WWRffnyJWy/+9bg5eXlsG1ubhb9mLLm\nmUw4IxPOyIQzMuGMTDjf3FuAoaGhsC0sLITt7u4u+fiBgYGwvfb/gvXNvcqEkQlnZMIZmXBGJpz3\nLvNUW1sbtq9fv4atsrIybEtLS8m/+dqvJPPlmUw4IxPOyIQzMuGMTDgjE84b5AmplyG+f/8etk+f\nPoXt5OQkbL97c2/qd187b5ArE0YmnJEJZ2TCGZlw3iBPaG1tDVvqSjJlcnIybG/xKvI5PJMJZ2TC\nGZlwRiackQlX9leXzc3NYVtZWcnrsamPiVpcXCz4mN4az2TCGZlwRiackQlnZMKV/dXl2NhY2Jqa\nmvJ67Pr6etie+k/jcuWZTDgjE87IhDMy4YxMuLK5uuzu7k7uExMTJT6S8uOZTDgjE87IhDMy4YxM\nOCMTrmxewujq6kru1dXVeT0+9Qbd29vbgo6pXHgmE87IhDMy4YxMOCMTrmyuLp9je3s7bH19fWHL\n5XKlOJxXzzOZcEYmnJEJZ2TCGZlwfu2NisqvvVEmjEw4IxPOyIQzMuGMTLgnX8KQisEzmXBGJpyR\nCWdkwhmZcP8Ch/7tq5Yl/GMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113bde470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncCQyEY5EJsKRyEQ4/wCxfYyTVKHJPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113bde080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_digit(test_set_x[0])\n",
    "draw_digit(predict1.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelFromAE = L.Classifier(MNISTMLPerceptronDropout())\n",
    "modelFromAE.predictor.l1 = a1.l1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.09000000357627869\n",
      "100 0.8100000023841858\n",
      "200 0.9100000262260437\n",
      "300 0.800000011920929\n",
      "400 0.9599999785423279\n",
      "500 0.949999988079071\n",
      "600 0.9100000262260437\n",
      "700 0.9200000166893005\n",
      "800 0.9599999785423279\n",
      "900 0.9700000286102295\n",
      "1000 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(modelFromAE)\n",
    "\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    batch_y = Variable(train_set_y[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(modelFromAE, batch_x, batch_y)\n",
    "    if step % 100 == 0:\n",
    "        print(step, modelFromAE.accuracy.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度 → 0.9546999931335449\n"
     ]
    }
   ],
   "source": [
    "modelFromAE(Variable(test_set_x),Variable(test_set_y))\n",
    "print(\"精度 →\",modelFromAE.accuracy.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "階層がそれほど深くないからか、あまり意味がなかった？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.07999999821186066\n",
      "100 0.9800000190734863\n",
      "200 0.9900000095367432\n",
      "300 0.9700000286102295\n",
      "400 0.9599999785423279\n",
      "500 0.9800000190734863\n",
      "600 1.0\n",
      "700 0.9800000190734863\n",
      "800 0.9800000190734863\n",
      "900 0.9800000190734863\n",
      "1000 1.0\n",
      "精度 → 0.9765999913215637\n"
     ]
    }
   ],
   "source": [
    "modelFromAE = L.Classifier(MNISTMLPerceptron())\n",
    "modelFromAE.predictor.l1 = a1.l1.copy()\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(modelFromAE)\n",
    "\n",
    "batch_size = 100\n",
    "for step in range(1001):\n",
    "    batch_index = np.random.randint(len(train_set[0])-batch_size)\n",
    "    batch_x = Variable(train_set_x[batch_index:batch_index+batch_size])\n",
    "    batch_y = Variable(train_set_y[batch_index:batch_index+batch_size])\n",
    "    optimizer.update(modelFromAE, batch_x, batch_y)\n",
    "    if step % 100 == 0:\n",
    "        print(step, modelFromAE.accuracy.data)\n",
    "modelFromAE(Variable(test_set_x),Variable(test_set_y))\n",
    "print(\"精度 →\",modelFromAE.accuracy.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "悩ましい。。。何もやらないほうが制度が高い。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
